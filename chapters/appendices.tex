\chapter*{\Large Appendices}
\addcontentsline{toc}{chapter}{Appendices}
\chaptermark{Appendices}
\numberwithin{equation}{section}
\makeatletter
\renewcommand\thesection{\@Alph\c@section}
\makeatother

\section{Helpful results from analysis and topology} \label{sec:helpful-analysis}
\begin{prop} \label{prop:subseq-further-subseq-top-space}
    In a given topological space $X$, a sequence $\{x_n\}$ converges to $x$ if and only if every subsequence of $x_n$ has a further subsequence that converges to $x$.
\end{prop}
\begin{proof}
    The only if direction is obvious. To prove the if direction, suppose $x_n \not\to x$ under the assumption. Let $n_0 = 1$. There is some (open) neighborhood $U$ of $x$ such that for every $k\in \N$, we can find a smallest $n_k \geq n_{k-1}$ such that $x_{n_k} \notin U$. However, this implies that the subsequence $\{x_{n_k}\}$ of $\{x_n\}$ does not have a subsequence that converges to $x$, which contradicts the assumption.
\end{proof}

% \begin{fact}
%     In a given metric space $(X,d)$, $x_n \to x$ if and only if $\limsup_n d(x_n,x) = 0$.
% \end{fact}

% The proof is obvious, but using the triangular inequality of limit superior sometimes give cleaner arguments.

\begin{prop}[(sequential criterion for limits and continuity)]
    
\end{prop}

\begin{prop} \label{prop:discont-countable}
    For an increasing function $f\colon \R\to \R$, the set of discontinuities is countable.
\end{prop}

\begin{prop}\label{prop:dist-set-cont}
    Given a set $A$ in a metric space $(X,d)$, the function $d(\blank,A)\colon X \to [0,\infty)$ given by \[
        d(x,A) = \inf\{d(x,y) : y\in A\}
    \] is a continuous function. Also $d(x,A) = 0$ if and only if $x \in \ol{A}$.
\end{prop}

\begin{namedthm}[Abel's theorem]
    Assume $S(x) = \sum_{n=0}^\infty a_n x^n$ converges, and let $R$ be the radius of convergence \[ \frac{1}{\limsup_n {\abs{a_n}}^{1/n}}.\] If the series converges at $x = R > 0$, then the series converges uniformly over $[0,R]$. In particular this implies that $S(x)$ is continuous at $R^-$.
\end{namedthm}

\begin{prop}
    Infinite subset of a compact set has a limit point.
\end{prop}

\begin{prop}\label{prop:closed-compact-intersect}
    Intersection of a closed set and a compact set is compact.
\end{prop}

\begin{prop}\label{prop:compact-subset-Hausdorff}
    Compact subsets of a Hausdorff space are closed.
\end{prop}

\begin{prop}
    For $A \subseteq B \subseteq X$, where $A$ and $B$ are given the subspace topology of $X$. Then $A$ is dense in $X$ if and only if $A$ is dense in $X$.
\end{prop}

Note that $A$ is dense in $B$ means that $\clos{A} \supseteq B$.

\begin{namedthm}[Urysohn's lemma]
    Let $X$ be normal. If $A$ and $B$ are two disjoint closed sets in $X$, then there exists a continuous function $f\colon X \to [0,1]$ such that $f(A)=\{0\}$ and $f(B) = \{1\}$.
\end{namedthm}

If $X$ is a metric space (which is necessarily normal), then this is easy. We may just take \[f(x) = \frac{d(x,A)}{d(x,A) + d(x,B)}.\]

Here is a sketch of the standard proof of this important result in topology. Based on normality, we may inductively dyadically choose (i.e., using \textsf{DC}) an increasing sequence of sets $U_{j/2^n}$ that ``lie between'' $A$ and $B$: \[
    A \subseteq U_{1/2^n},\quad \dotsc\quad ,\ol{U}_{(j-1)/2^n} \subseteq U_{j/2^n},\quad \dotsc\quad , \ol{U}_{(2^{n-1})/2^n} \cap B =\emptyset.
\]
One can show that the function $f\colon X\to [0,1]$ given by \[
    f(x) = \begin{cases}
        \inf\{r : x\in U_r\} & \text{if the set is nonempty}, \\
        1 & \text{otherwise}.
    \end{cases}
\] is continuous.

The use of \textsf{DC} can be avoided when $X$ is second countable and regular, by the constructive proof of the following proposition.

\begin{prop}
    Every second countable regular space is normal.
\end{prop}

\begin{namedthm}[Urysohn metrization theorem]
    Every second countable regular space is metrizable.
\end{namedthm}

In particular, every lcscH space is metrizable.

\begin{prop} \label{prop:2nd-count-separable-lindlof} \leavevmode
    \begin{enumerate}
        \item A second countable space is separable; the converse is also true when we are in a metric space.
        \item A second countable space is Lindelöf, the converse is also true when we are in a metric space.
    \end{enumerate}
\end{prop}

A subspace of a Lindelöf space is not necessarily Lindelöf. Therefore it is sometimes useful to introduce the definition of a \df{hereditary Lindelöf} space, whose subspaces are all Lindelöf.

\begin{fact} \label{fact:Lind-property-2nd-count-space}
    A second countable space is hereditary Lindelöf, since any subspace of a second countable space is second countable.
\end{fact}

% \begin{prop} Bogachev 1.2.13
%     Every collection of open sets in a separable metric space contains an at most countable subcollection with the same union.
% \end{prop}

\begin{thm}[(Characterization of compactness in metric spaces)]\label{thm:char-thm-compact}
    A subset of a metric space is compact if and only if it is sequentially compact if and only if it is totally bounded and complete.
\end{thm}

\begin{prop} \label{prop:unique-dense-subset}
    Let $f,g\colon X \to Y$ be two continuous functions, where $X$ is a topological space and $Y$ is Hausdorff. If $f$ and $g$ agree on a dense subset of $X$, then $f = g$ on $X$.
\end{prop}

\begin{thm} \label{thm:ext-unif-cont-func}
    Let $X$ and $Y$ be metric spaces, with $Y$ being complete. Let $D$ be a dense subspace of $X$, and $f\colon D \to Y$ be a uniformly continuous function. Then there is a unique extension of $f$ to $F\colon X \to Y$, such that $F$ is still uniformly continuous.
\end{thm}
\begin{proof}
    Any $x \in X$ can be written as the limit of a sequence $\{x_n\}\subseteq D$. For each such sequence $\{x_n\}$, by uniform continuity it holds that for all $\epsilon > 0$, for all $m,n\in \N$ there exists $\delta > 0$ such that \[
        \abs{x_n - x_m} < \delta \implies \abs{f(x_n) - f(x_m)} < \epsilon.
    \] Since $\{x_n\}$ is a convergent sequence it also holds that there is some $N_\delta \in \N$ such that for all $m > n\geq N_\delta$, it holds that $\abs{x_n - x_m} < \delta$. With these information combined, we get $\{f(x_n)\}$ is a Cauchy sequence in $Y$, which is complete. Therefore $\lim_n f(x_n)$ exists.

    Now let us show that $\lim_n f(x_n) = \lim_n f(w_n)$ is the same for any $\{x_n\}$ and $\{w_n\}$ that approach $x$. We know $x_n - w_n \to 0$, and hence (using the same reasoning as above) $f(x_n) - f(w_n) \to 0$.

    Now define $F(x) = \lim_n f(x_n)$ for any $\{x_n\}$. The function $F$ is (sequentially) continuous everywhere. It is clear $F|_D = f$, and such an extension must be unique by \cref{prop:unique-dense-subset}.

    It remains to show that $F$ is uniformly continuous. Consider $a,b\in X$, which are respectively limits of some $\{a_n\}$ and $\{b_n\}$ in $D$. We want to show that for any $\epsilon > 0$, for all $a,b\in X$, there exists $\delta > 0$ such that \[
        \abs{a - b} < \delta \implies \abs{F(a) - F(b)} < \epsilon.
    \] We leave it to the reader to use the uniform continuity of $F|_D$, $F(a) = \lim_n F(a_n)$, and the triangular inequality to meet the above inequality.
\end{proof}

We emphasize $X$ and $D$ here have the same metric structure. Compare this result with the upcoming \nameref{thm:hahn-banach}.

\begin{namedthm}[Uniqueness theorem] \label{thm:uniqueness-cplx}
    Let $G$ be a region (i.e., nonempty open connected subset of $\C$). If $f$ and $g$ are both holomorphic in $G$, and $f$ and $g$ agree on some $S \subseteq G$ that has a limit point in $G$, then $f$ and $g$ agrees everywhere on $G$.
\end{namedthm}

\begin{namedthm}[Mean value inequality for $\R^d$-valued functions {\cite[Theorem 5.19]{Rudin_principles_1976}}]
    Let $f\colon [a,b] \to \R^d$ be continuous, and $f$ be differentiable in $(a,b)$, then there exists $x \in (a,b)$ such that \[
        \abs{f(b) - f(a)} \leq (b-a) \sup_{a< x < b} \abs{b - a}.
    \]
\end{namedthm}
\begin{proof}
    Apply the ordinary mean-value theorem to the continuous $\phi\colon [a,b] \to \R$ defined by \[
        \phi(t) = \inp{f(b) - f(a)}{f(t)},
    \] and use the \nameref{thm:Cauchy-Schwarz}.
\end{proof}

\begin{namedthm}[Mean value inequality for $\C$-valued functions]
    Let $f$ be defined on an open set containing the segment $\gamma^*$ between $z$ and $z_0$, and $f$ be differentiable everywhere on $\gamma^*$. Then \[
        \frac{\abs{f(z) - f(z_0)}}{\abs{z - z_0}} \leq \sup_{w\in \gamma^*}\abs{f'(w)}.
    \]
\end{namedthm}
\begin{proof}
    This follows from the Fundamental theorem of calculus for parameterized paths and the Estimation lemma: \begin{align*}
         \abs{f(z) - f(z_0)} & = \biggl\vert \int_\gamma f'(w)\,dw\biggr\vert \\ & \leq \sup_{w\in \gamma^*} \abs{f'(w)}\cdot \operatorname{length}(\gamma) \\ & = \sup_{w\in \gamma^*} \abs{f'(w)}\cdot \abs{z - z_0}. \qedhere
    \end{align*}
\end{proof}

\begin{namedthm}[Uniform convergence of derivatives {\cite[Theorem~7.17]{Rudin_principles_1976}}\footnote{Also see Theorem~8.15 and Remark~8.16 in \cite{Krantz_2022}.}]
    Let $f_n \colon (a,b)\to \R$ be a sequence of differentiable functions that converges pointwise to $f$. If $f_n'$ converges uniformly to some function $g$, then $f_n\to f$ uniformly and also $f' = g$.
\end{namedthm}
The key part of the proof is the use of the mean value theorem on $f_n' - f_m'$. 

\section{Banach spaces}
Let $X$ and $Y$ be two normed spaces in this section.

\begin{exa}
    $(C_b(X),\nm{\blank}_u)$
    $(C_0(X),\nm{\blank}_u)$
\end{exa}

We use $\mathcal{L}(X,Y)$ for the space of linear maps between normed spaces $X$ and $Y$, and we denote $\mathcal L(X,\mathbf F)$ by $X^*$, called the dual space of $X$.
\begin{prop}
    For $T \in \mathcal{L}(X,Y)$, then $T$ is bounded if and only if it is continuous if and only if it is continuous at any point of $X$.
\end{prop}

\begin{fact}
    A bounded linear operator is Lipschitz continuous.
\end{fact}

\begin{namedthm}[Riesz' lemma]
    
\end{namedthm}

\begin{thm}
    The closed unit ball is compact in a normed space if and only if the normed space is finite-dimensional.
\end{thm}

\begin{namedthm}[Hahn–Banach theorem] \label{thm:hahn-banach}
    Let $X$ be a real vector space, and $p$ be a sublinear functional. 

    Let $X$ be a complex vector space, and $p$ be a seminorm.
\end{namedthm}

\begin{namedthm}[Hahn–Banach theorem in \textsf{ZF}]
    Let $X$ be a real topological vector space, and $p$ be a continuous sublinear functional. 
\end{namedthm}

\begin{prop}
    If $Y$ is complete, then $\mathcal{L}(X,Y)$ is complete. In particular the dual space of any normed space is complete.
\end{prop}

\begin{namedthm}[Uniform boundedness principle]
    
\end{namedthm}

\begin{namedthm}[Open mapping theorem]
    For two Banach spaces $X$ and $Y$, if $T\in \mathcal L(X,Y)$ is surjective, then the map is open.
\end{namedthm}

\begin{cor}
    For two Banach spaces $X$ and $Y$, if $T\in \mathcal L(X,Y)$ is bijective, then the inverse $T^{-1}$ is also a bounded linear map.
\end{cor}

\begin{namedthm}[Closed graph theorem]
    For two Banach spaces $X$ and $Y$, if $T\in \mathcal L(X,Y)$ is closed, then the operator is bounded.
\end{namedthm}

\begin{namedthm}[Baire category theorem]
    Every complete (pseudo)metric space is a Baire space, i.e., a space where a countable intersection of nowhere dense sets is nowhere dense. This implies that a complete metric space is not the countable union of nowhere dense sets.

    The above result also holds for all locally compact regular spaces, which includes locally compact Hausdorff spaces.
\end{namedthm}

\section{Hilbert spaces}
A \df{Hilbert space} is an inner space with a complete metric induced from the inner product. We assume the underlying field is $\C$ for this section.

\begin{prop}
    An inner product space (resp.\ Hilbert space) is a normed space (resp.\ Banach space) with the \df{parallelogram law}: \[
        \nm{x - y}^2 + \nm{x + y}^2 = 2 \nm{x}^2 + 2\nm{y}^2 \quad \text{for all }x\text{ and }y.
    \]
\end{prop}

\begin{namedthm}[Cauchy--Schwarz inequality] \label{thm:Cauchy-Schwarz}
    On an inner product space $V$, we have \[
        \abs{\inp{u}{v}} \leq \nm{u}\nm{v},
    \] with equality if and only if one is a scalar multiple of the other.
\end{namedthm}
\begin{proof}
    Expand the nonnegative expression $f(\lambda) \coloneqq \nm{u+\lambda v}^2$ for all $\lambda\in \R$, which contains the desired real part of the inner product and has discriminant $\leq 0$. After getting \[
        \abs{\Re \inp{u}{v}} \leq \nm{u}\nm{v},
    \] replace $u$ by $\frac{\abs{\inp{u}{v}}}{\inp{u}{v}}$\footnote{This change-of-direction trick is a prevalent trick to extend results proved over real vector spaces to over complex vector spaces}.
\end{proof}

With the additional topological assumption that Hilbert spaces have complete metric, most of the results for finite-dimensional inner product spaces carry over to infinite dimensional Hilbert spaces. To motivate the upcoming results, it is recommended to review their finite-dimensional analogs, and understand why these results should be true.

\begin{namedthm}[Projection theorem] \label{thm:proj-Hilbert} Given a Hilbert space $H$ and a closed convex subset $Y$,
\begin{enumerate} 
    \item for each $x \in H$ there exists a unique \[
        y = \argmin_{z \in Y} \nm{x - z},
    \] which we call the \df[Hilbert space projection]{projection} of $x$ to $Y$, denoted by $\pi_Y(x)$.

    Moreover, the projection $y = \pi_Y(x)$ is characterized by the property \begin{equation} \label{eq:proj-cc-set-char}
        \Re \inp{x - y}{z - y} \leq 0\quad\text{for all }z\in Y.
    \end{equation}
    \item if $Y$ is furthermore a closed subspace of $H$, then the characterization above for $\pi_Y(x)$ may be further replaced by \begin{equation} \label{eq:proj-closed-sub-char}
        \inp{x- y}{z} = 0\quad \text{for all }z\in Y.
    \end{equation}
\end{enumerate}
\end{namedthm}
\begin{proof} \leavevmode
    \begin{enumerate}
        \item Let $D = \inf_{z\in Y}\nm{x-z}$, and since $Y$ is close, we may choose a sequence $\{y_n\}$ such that $\nm{x - y_n} \to D$ from above. Our goal is to show that it is a Cauchy sequence, and hence converges.

        For $n > m \geq 1$, by the parallelogram law we have \[
            \nm{y_n -y_m}^2 = 2\nm{x - y_n}^2 + 2 \nm{x - y_m}^2 - 4 \Bigl\Vert x - \frac{y_n + y_m}{2} \Bigr\Vert^2.
        \] Since $\frac{y_n + y_m}{2} \in Y$ by convexity, we have \[
             \nm{y_n -y_m}^2 \leq 2\nm{x - y_n}^2 + 2 \nm{x - y_m}^2 - 4D^2.
        \] It follows that as $n, m \to \infty$, $\nm{y_n - y_m}\to 0$, as desired. Since closed subset of a complete metric space is complete, $y_n$ should converges to some $y \in Y$. By $\nm{x - y_n} \to \nm{x - y}$ we conclude that $\nm{x - y} = D$.

        To show the uniqueness of $y$: for two $y$ and $y'$ that attains the infimum $D$, use the parallelogram law again we have \begin{align*}
            \nm{y -y'}^2 & = 2\nm{x - y}^2 + 2 \nm{x - y'}^2 - 4 \Bigl\Vert x - \frac{y + y'}{2} \Bigr\Vert^2 \\
            & \leq 2D^2 + 2D^2 - 4D^2 = 0.
        \end{align*}
        
        Now we want to show this $y$ satisfies \eqref{eq:proj-cc-set-char}. Let $z \in Y$ be arbitrary. To get (the real part of) the inner product\footnote{like in the proof of Cauchy--Schwarz} we consider the expression \[
            f(\lambda) \coloneqq \nm{\lambda(z-y) - (x-y)}^2 = \nm{y +\lambda(z - y)-x}^2.
        \] For all $\lambda\in [0,1]$, by convexity $y + \lambda(z-y) \in Y$, and hence $f(\lambda) \geq \nm{x - y}^2$. Now expanding $f(\lambda)$ gives us \[
            \lambda^2 \nm{z - y}^2 - 2\lambda\Re \inp{x-y}{z-y} \geq 0.
        \] Hence \[ \lambda \nm{z - y}^2 \geq 2\Re \inp{x-y}{z-y} \quad\text{for all }\lambda\in [0,1],
        \] and take $\lambda \to 0^+$ gives us \eqref{eq:proj-cc-set-char}.

        For the converse, now suppose \eqref{eq:proj-cc-set-char} holds for some $y \in Y$, and we want to show \[
            \nm{x - y} \leq \nm{x - z}\quad \text{for all }z\in Y.
        \] We trace our steps back: first, \[
            2\Re \inp{x-y}{z-y} \leq 0\leq \nm{z - y}^2.
        \] It follows that \[
            \nm{x - y}^2 \leq \nm{(z - y) - (x - y)}^2,
        \] as desired.
        \item To show the second part, it suffice to prove that \eqref{eq:proj-cc-set-char} and \eqref{eq:proj-closed-sub-char} are equivalent. Because $Y$ is now a subspace of $H$, equation \eqref{eq:proj-cc-set-char} is equivalent to \[
            \Re\inp{x-y}{z} = 0\quad\text{for all }z\in Y.
        \] Notice that \[
            \Im\inp{x-y}{z} = \Re -i\inp{x-y}{z} = \Re \inp{x-y}{iz},
        \] which completes the proof. \qedhere
    \end{enumerate}
\end{proof}

\begin{prop}
    For $H$ and its closed subspace $Y$, $\pi_Y$ has the following properties:
    \begin{enumerate}
        \item $\pi_Y \in \mathcal{L}(H)$;
        \item $\pi_Y^2 =\pi_Y$;
        \item $\ran \pi_Y = Y$ and $\nul \pi = Y^\perp$;
        \item $\nm{\pi_Y(x)} \leq \nm{x}$ for all $x \in H$.
    \end{enumerate}
\end{prop}

\begin{namedthm}[Riesz representation theorem]
    For each linear functional $f \in H^*$, there exist a unique $v \in H$ such that \[
        f(x) = \inp{x}{v}\quad\text{for all }x\in H.
    \] Moreover $\nm{f} = \nm{v}$.
\end{namedthm}

An \df{orthonormal system} $\{e_\alpha\}_{\alpha \in A}$ is a possibly infinite collection of vectors such that \[\inp{e_\alpha}{e_\beta} = \begin{cases}
    1 & \alpha = \beta, \\
    0 & \alpha \neq \beta.\end{cases}
\]

The order of $\alpha$ does not matter when $A$ is countable.

\begin{prop}
    Suppose we have a finite orthonormal system $\{e_j\}_{j=1}^n$ that spans $Y$. If $Y \subseteq H$. Then the projection of any $x\in H$ is explicitly $\pi_Y(x) = \sum_{j=1}^n \inp{x}{e_j}e_j$.
\end{prop}

\begin{prop}
    $\sum_{\alpha \in A}\inp{x}{e_\alpha} e_\alpha$ 
\end{prop}

\begin{thm}
Let $\{e_\alpha\}_{\alpha\in I}$ be an orthonormal system, then \begin{enumerate}
    \item $\sum_{\alpha \in A} \inp{x}{e_\alpha}^2 \leq \nm{x}^2$, which is known as \df{Bessel's inequality};
    \item the equality above holds if and only if the series $x = \sum_{\alpha \in A}\inp{x}{e_\alpha} e_\alpha$ in $H$.
\end{enumerate}
\end{thm}

Orthonormal decomposition

Parseval's identity

Gram--Schmidt process

\begin{thm}[(complete orthonormal system)]
    $\{e_\alpha\}_{\alpha \in A}$ is an orthonormal basis of $H$ if and only if $\operatorname{span}\{e_\alpha\}$ is dense in $H$.
\end{thm}

\begin{thm}
    $H$ has a countable orthonormal basis if and only if $H$ is separable. Additionally in this case, all bases have the same cardinality.
\end{thm}



\section{Weak topologies and topological vector spaces}

dual pairing

initial topology and net convergence
$f\colon X \to Y$ is continuous if and only if for every $x_\alpha \to x$, we have $f(x_\alpha) \to f(x)$.

A related results $x_\alpha \to x$ in the initial topology on $X$ generated by $\mathcal{F} = \{f_\beta \colon X \to Y_\beta\}_{\beta \in B}$ if and only if $f(x_\alpha) \to f(x)$ for all $f \in \mathcal{F}$. This is true for both nets and sequences.

convergence in product spaces

If the target spaces $Y_\beta$'s are all Hausdorff, then $X$ is Hausdorff if and only if the collection $\F$ separates points in $X$.

The subbasis of $\F$ can be specified by $f_\beta^{-1}(V)$, where $V$ ranges over any open sets of $Y_\beta$, for any $\beta \in B$. One may take $Y$ to be any basic or subbasic open set as well, by the property of the preimage. If $\F$ consists of only one function $f$, then the preimage $f^{-1}$ takes (subbasic/basic) open sets in $Y$ precisely to (subbasic/basic) open sets in $X$.

Bogachev 1.6.5 6 8

$x_n \to x$ weakly (i.e., converges in the weak topology) if and only if for all $f \in X^*$, $f(x_n) \to f(x)$



$f_n \to f$ weakly (i.e., converges in the weak-star topology) if and only if for all $x \in X$, $\hat{x}(f_n) = f_n(x) \to \hat{x}(f) = f(x)$

The basis for $\sigma(X,X^*)$ is usually expressed in the following explicity way.

For any $x_0\in X$, a neighborhood base for $x_0$ is given by \[
        \bigcap_{j=1}^n f^{-1}_j\bigl(f_j(x_0) - \epsilon, f_j(x_0) + \epsilon\bigr),
\] or equivalently,
\[
    \bigl\{x \in X: \abs{f_j(x - x_0)} < \epsilon \text{ for all } j \in [n]\bigr\},
\]
for any finite number of $f_j$'s and $\epsilon > 0$.

You push $x_0$ to the target field $\mathbf F$, vary $f_j(x_0)$ in a small neighborhood in $\F$, and then push back to $X$ to get a neighborhood for $x_0$.

The weak and weak-star topology can alternatively be seen as \emph{seminorm topologies}, which we discuss here. Say $X$ is a vector space, on which we have $\{p_\alpha\}_{\alpha \in A}$ as a family of seminorms. The \df[topology generated by a family of seminorms]{topology on $X$ generated by} $\{p_\alpha\}$ is the initial topology with respect to the family of functions \[\{x \mapsto p_\alpha(x - x_0) : x_0 \in X, \alpha \in A\}.\] Be very careful that this is \emph{not} the initial topology that makes all $p_\alpha(\blank)$ continuous. Rather, due to the vector space structure of $X$, the translation by $y$ in the functions $x \mapsto p_\alpha (x-y)$ is an important requirement, such that $(x,y) \mapsto x + y$ and $(\lambda,x) \mapsto \lambda x$ are continuous. A vector space with a topology that makes vector addition and scalar multiplication continuous is called a \df{topological vector space}.

A topological vector space whose topology has a basis consisting of convex sets is called a locally convex topological vector space. The vector space topology induced from seminorms is locally convex.

The \df{strong operator topology} on $\mathcal L(X,Y)$ is generated by the evaluation maps $\{T \mapsto Tx : x\in X\}$, where $Y$ is endowed with the norm topology. $T_n \to T$ in the strong operator topology if and only if $T_n x \to Tx$.

The \df{weak operator topology} on $\mathcal L(X,Y)$ is generated by the maps $\{T \mapsto f(Tx) : x\in X, f\in Y^*\}$ to the dual space of $Y$. $T_n \to T$ in the weak operator topology if and only if for all $x \in X$ and $f \in Y^*$, $f(T_n x) \to f(T x)$, which is equivalent to saying that $T_n x \to T$ weakly.

\begin{namedthm}[Sequential Banach--Alaoglu--Bourbaki theorem] \label{label:seq-Alaoglu}
    For a separable normed vector space $X$, every bounded sequence in $X^*$ has a weak-star convergent subsequence (i.e., $X^*$ is weak-star sequentially compact).
\end{namedthm}

or the generalized Helly selection theorem, for the reasons we discussed after \cref{lem:Helly-pre}

\begin{namedthm}[Banach--Alaoglu--Bourbaki theorem]
    For a normed vector space $X$, every closed and bounded subset of $X^*$ is weak-star compact.
\end{namedthm}

metrizability

\begin{namedthm}[Tychonoff's theorem]
    Arbitrary product of compact topological spaces is compact.
\end{namedthm}

\begin{thm}[(Tychonoff's theorem for countable product)]
    Countable product of compact topological spaces is compact.
\end{thm}

Tychonoff's theorem is equivalent to the axiom of choice.

See discussion in  \cite[Section~4.8]{Herrlich_2006}.

If the product is finite, then no choice is needed.

\begin{xca}
    Give a direct proof of Tychonoff's theorem for the countable product of compact metric spaces, using metrization.
\end{xca}

\begin{thm}
    The countable product of sequentially compact spaces is sequentially compact.
\end{thm}

Every weakly convergent sequence is norm bounded

\section{Adjoint and compact operators}

unitary operators

annihilators

\begin{namedthm}[Closed range theorem]
    
\end{namedthm}

% \section{Weak convergence of general measures} \label{sec:weak-conv-general-meas}

\section{Topological groups and Haar measures}

\section{A gentle introduction to optimal transport}

\section{Facts and tools in probability}
$e^x \geq x + 1$ log sum inequality
$\frac{x-1}{x}\leq \log x \leq x - 1$ for $x > 0$

\[\frac{1}{x}\leq \log\Bigl(\frac{x}{x-1}\Bigr) = \int_{x-1}^x \frac{1}{t}\,dt\leq \frac{1}{x-1}\]

Therefore for all $n$, \[
    \sum_{x=2}^n \frac{1}{x} \leq \log n = \int_1^n \frac{1}{t}\,dt \leq \sum_{x=2}^n \frac{1}{x-1}
\]
Hence \[
    \log(n+1) \leq \sum_{x=1}^n\frac{1}{x}\leq \log(n) +1
\]

\begin{prop}
    For two independent random variables $X\sim \Exp(\lambda)$ and $Y\sim \Exp(\mu)$, these hold. \begin{enumerate}
        \item $\min\{X,Y\} \sim \Exp(\lambda + \mu)$;
        \item $P(X \leq Y) = \frac{\lambda}{\lambda + \mu}$;
        \item $\min\{X,Y\}$ and $\{X\leq Y\}$ are independent.
    \end{enumerate}
\end{prop}

\begin{proof}
    $P(X > t, Y > t) = P(X > t) P(Y > t) = e^{-(\lambda + \mu)t}$

\begin{align*}
    P(X - Y \leq t) & = \int_{-\infty}^\infty f_X(t+y) f_{-Y}(-y)\,dy \\
    & = \lambda \mu e^{-\lambda t} \int_{-\infty}^\infty e^{(-\lambda - \mu)y}\ind\{y \geq 0, t + y\geq 0\}\,dy \\
    & = \frac{\lambda \mu}{\lambda + \mu}e^{-\lambda t} e^{(-\lambda - \mu)y}\bigr]_{y=\min\{0,-t\}}^\infty
\end{align*}
Hence \[
    P(X - Y \leq t) = \begin{cases}
      \frac{\lambda \mu}{\lambda + \mu}e^{-\lambda t}  & \text{if } t \geq 0, \\
      \frac{\lambda \mu}{\lambda + \mu}e^{\mu t}  & \text{if } t< 0.
    \end{cases}
\]
    \[P(X > t,Y > t,X \leq Y) = P(X > t, Y > t) P(X \leq Y)\]

LHS = $\int_{t}^\infty \mu e^{-\mu y} \int_{t}^y \lambda e^{-\lambda x}\,dx\,dy$

% \begin{align*}
%     P(Y \geq X > x) & = P(X \leq Y)P(\min\{X,Y\} > x) + P(X > Y)P(X >x) \\
%     & = \frac{\lambda}{\lambda + \mu}\exp(-\lambda -\mu) + \frac{\mu}{\lambda + \mu}P(X > x \giv X > Y)
%     \\ P(X > Y >y) & = 
% \end{align*}

\end{proof}

The converse is also true Poisson thinning


\begin{namedthm}[Birthday problem]
    
\end{namedthm}

\begin{namedthm}[Pólya's urn]
    
\end{namedthm}

\begin{namedthm}[Gambler's ruin]
    
\end{namedthm}

\begin{namedthm}[Coupon collector's problem]
    
\end{namedthm}

\begin{namedthm}[Simple random walks on $\Z^d$]
    
\end{namedthm}

\begin{namedthm}[Bernoulli bond percolation]
    
\end{namedthm}

\printnomenclature